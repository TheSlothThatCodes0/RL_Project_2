agent:
  gradient_steps: 1
  batch_size: 32
  discount_factor: 0.99
  polyak: 0.005
  learning_rate: 0.001
  learning_rate_scheduler: null
  learning_rate_scheduler_kwargs: {}
  state_preprocessor: null
  state_preprocessor_kwargs: {}
  random_timesteps: 1000
  learning_starts: 1000
  update_interval: 1
  target_update_interval: 1000
  exploration:
    initial_epsilon: 1.0
    final_epsilon: 0.05
    timesteps: 50000
  rewards_shaper: null
  mixed_precision: false
  experiment:
    directory: /home/pi0/RL_GOOD/logs/skrl
    experiment_name: 2025-12-10_21-21-02_ppo_torch
    write_interval: auto
    checkpoint_interval: auto
    store_separately: false
    wandb: false
    wandb_kwargs: {}
  class: DQN
  models:
    policy:
      class: RGBD_DQN
      clip_actions: false
    target:
      class: RGBD_DQN
      clip_actions: false
  memory:
    class: RandomMemory
    memory_size: 1000
seed: 42
models:
  policy:
    class: RGBD_DQN
    clip_actions: false
  target:
    class: RGBD_DQN
    clip_actions: false
trainer:
  timesteps: 100000
  headless: true
  close_environment_at_exit: false
