[INFO] Saving console logs to: /home/pi0/RL_GOOD/logs/skrl/2025-12-11_01-41-55_ppo_torch/output.log
Setting seed: 42
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.01
	Rendering step-size   : 0.02
	Environment step-size : 0.02
[INFO]: Time taken for scene creation : 4.313398 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 8
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : []
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 1.790858 seconds
[INFO] Command Manager:  <CommandManager> contains 1 active terms.
+------------------------------------------+
|           Active Command Terms           |
+-------+-------------+--------------------+
| Index | Name        |        Type        |
+-------+-------------+--------------------+
|   0   | object_pose | UniformPoseCommand |
+-------+-------------+--------------------+

[INFO] Event Manager:  <EventManager> contains 1 active terms.
+--------------------------------------+
| Active Event Terms in Mode: 'reset'  |
+---------+----------------------------+
|  Index  | Name                       |
+---------+----------------------------+
|    0    | reset_all                  |
|    1    | reset_object_position      |
+---------+----------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 2 active terms.
+------------------------------------+
|   Active Action Terms (shape: 8)   |
+-------+----------------+-----------+
| Index | Name           | Dimension |
+-------+----------------+-----------+
|   0   | arm_action     |         7 |
|   1   | gripper_action |         1 |
+-------+----------------+-----------+

[INFO] Observation Manager: <ObservationManager> contains 1 groups.
+--------------------------------------------+
| Active Observation Terms in Group: 'policy' |
+----------+----------+----------------------+
|  Index   | Name     |        Shape         |
+----------+----------+----------------------+
|    0     | rgb      |    (224, 224, 3)     |
|    1     | depth    |    (224, 224, 1)     |
+----------+----------+----------------------+

[INFO] Termination Manager:  <TerminationManager> contains 3 active terms.
+----------------------------------------+
|        Active Termination Terms        |
+-------+---------------------+----------+
| Index | Name                | Time Out |
+-------+---------------------+----------+
|   0   | time_out            |   True   |
|   1   | object_dropping     |  False   |
|   2   | object_reached_goal |  False   |
+-------+---------------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 3 active terms.
+----------------------------------+
|       Active Reward Terms        |
+-------+-----------------+--------+
| Index | Name            | Weight |
+-------+-----------------+--------+
|   0   | reaching_object |    1.0 |
|   1   | lifting_object  |     15 |
|   2   | object_grasped  |    5.0 |
+-------+-----------------+--------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 0 active terms.
+----------------------+
| Active Curriculum Terms |
+-----------+----------+
|   Index   | Name     |
+-----------+----------+
+-----------+----------+

[INFO]: Completed setting up the environment...
[INFO] Found PixelActionWrapper with 2346 actions. Using Discrete action space for Agent.
[DEBUG] Env Action Space: Box(-inf, inf, (8,), float32)
[DEBUG] Agent Action Space: Discrete(2346)
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/pi0/RL_GOOD/IsaacLab/source/isaaclab_tasks/isaaclab_tasks/utils/hydra.py", line 101, in hydra_main
    func(env_cfg, agent_cfg, *args, **kwargs)
  File "/home/pi0/RL_GOOD/robotis_lab/scripts/reinforcement_learning/skrl/train.py", line 379, in main
    trainer.train()
  File "/home/pi0/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/skrl/trainers/torch/sequential.py", line 86, in train
    self.single_agent_train()
  File "/home/pi0/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/skrl/trainers/torch/base.py", line 182, in single_agent_train
    states, infos = self.env.reset()
                    ^^^^^^^^^^^^^^^^
  File "/home/pi0/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/skrl/envs/wrappers/torch/isaaclab_envs.py", line 75, in reset
    tensorize_space(self.observation_space, observations["policy"])
  File "/home/pi0/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/skrl/utils/spaces/torch/spaces.py", line 114, in tensorize_space
    return {k: tensorize_space(s, x[k], device=device) for k, s in space.items()}
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi0/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/skrl/utils/spaces/torch/spaces.py", line 114, in <dictcomp>
    return {k: tensorize_space(s, x[k], device=device) for k, s in space.items()}
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi0/miniconda3/envs/env_isaaclab/lib/python3.11/site-packages/skrl/utils/spaces/torch/spaces.py", line 83, in tensorize_space
    return x.reshape(-1, *space.shape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 224, 224, 1]' is invalid for input of size 18768

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[INFO] Closing simulation app...

[INFO] SIGINT (Ctrl+C) detected via signal handler.

[INFO] Saving agent checkpoint...
[INFO] Flushing TensorBoard writer...
[INFO] Agent saved to /home/pi0/RL_GOOD/logs/skrl/2025-12-11_01-41-55_ppo_torch/checkpoints/manual_save_agent.pt
[INFO] Generating reward graph...
[INFO] Reading logs from: /home/pi0/RL_GOOD/logs/skrl/2025-12-11_01-41-55_ppo_torch/events.out.tfevents.1765397522.pi0-X299-UD4-Pro.78475.0
[WARNING] 'Reward / Mean reward' not found in logs. Available tags: []
[INFO] Note: For very short runs, TensorBoard might not have written data yet.
[INFO] Exiting process immediately.
